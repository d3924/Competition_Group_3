method = "ridge",
tuneGrid = ridgeGrid,
trControl = ctrl,
)
ridgeTune
min(ridgeTune$results$RMSE)
ggplot(ridgeTune)
set.seed(2021)
lassoGrid <- expand.grid(lambda = c(0),
fraction = seq(.1, 1, length = 15))
lassoTune <- train(x = transformed_predictors, y = outcome_vector,
method = "enet",
tuneGrid = lassoGrid,
trControl = ctrl,
)
min(lassoTune$results$RMSE)
ggplot(lassoTune)
set.seed(100)
lassoGrid <- expand.grid(lambda = c(0),
fraction = seq(.1, 1, length = 15))
lassoTune <- train(x = transformed_predictors, y = outcome_vector,
method = "enet",
tuneGrid = lassoGrid,
trControl = ctrl,
)
min(lassoTune$results$RMSE)
ggplot(lassoTune)
View(competition_data)
set.seed(100)
enetGrid <- expand.grid(lambda = seq(0.0, 0.02, length = 5),
fraction = seq(.1, 1, length = 5))
enetTune <- train(x = low_noise, y = outcome_vector,
method = "enet",
tuneGrid = enetGrid,
trControl = ctrl,
)
min(enetTune$results$RMSE)
ggplot(enetTune)
lmTune$results$RMSE
nnetGrid <- expand.grid(
decay =seq(0),
size = c(3)
)
set.seed(100)
nnetTuneWeightDecay <- train(transformed_predictors, outcome_vector,
method = "nnet",
tuneGrid = nnetGrid,
trControl = ctrl,
linout = TRUE,
trace = FALSE
)
nnetTuneWeightDecay$results$RMSE
ggplot(nnetTuneWeightDecay)
nnetTuneWeightDecay$results$RMSE
nnetTuneWeightDecay$results$RMSE
nnetGrid <- expand.grid(
decay =seq(5, 20, 80),
size = c(3)
)
set.seed(100)
nnetTuneWeightDecay <- train(transformed_predictors, outcome_vector,
method = "nnet",
tuneGrid = nnetGrid,
trControl = ctrl,
linout = TRUE,
trace = FALSE
)
nnetTuneWeightDecay$results$RMSE
min(nnetTuneWeightDecay$results$RMSE)
ggplot(nnetTuneWeightDecay)
nnetGrid <- expand.grid(
decay =c(5, 20, 80),
size = c(3)
)
set.seed(100)
nnetTuneWeightDecay <- train(transformed_predictors, outcome_vector,
method = "nnet",
tuneGrid = nnetGrid,
trControl = ctrl,
linout = TRUE,
trace = FALSE
)
min(nnetTuneWeightDecay$results$RMSE)
ggplot(nnetTuneWeightDecay)
nnetGrid <- expand.grid(
decay =c(1,2,5),
size = c(3)
)
set.seed(100)
nnetTuneWeightDecay <- train(transformed_predictors, outcome_vector,
method = "nnet",
tuneGrid = nnetGrid,
trControl = ctrl,
linout = TRUE,
trace = FALSE
)
min(nnetTuneWeightDecay$results$RMSE)
ggplot(nnetTuneWeightDecay)
nnetGrid <- expand.grid(
decay =c(0,0.5,1),
size = c(3)
)
set.seed(100)
nnetTuneWeightDecay <- train(transformed_predictors, outcome_vector,
method = "nnet",
tuneGrid = nnetGrid,
trControl = ctrl,
linout = TRUE,
trace = FALSE
)
min(nnetTuneWeightDecay$results$RMSE)
ggplot(nnetTuneWeightDecay)
nnetGrid <- expand.grid(
decay =c(0.5,1,1.5),
size = c(3)
)
set.seed(100)
nnetTuneWeightDecay <- train(transformed_predictors, outcome_vector,
method = "nnet",
tuneGrid = nnetGrid,
trControl = ctrl,
linout = TRUE,
trace = FALSE
)
min(nnetTuneWeightDecay$results$RMSE)
ggplot(nnetTuneWeightDecay)
library(earth)
marsGrid <- expand.grid(.degree = 1,
.nprune = c(20, 30, 40, 50) # number of terms
)
marsOneDegreeFit <- train(low_noise, outcome_vector,
method = "earth",
tuneGrid = marsGrid,
trControl = ctrl
)
install.packages("earth")
install.packages("earth")
library(earth)
marsGrid <- expand.grid(.degree = 1,
.nprune = c(20, 30, 40, 50) # number of terms
)
marsOneDegreeFit <- train(low_noise, outcome_vector,
method = "earth",
tuneGrid = marsGrid,
trControl = ctrl
)
library(earth)
marsGrid <- expand.grid(.degree = 1,
.nprune = c(20, 30, 40, 50) # number of terms
)
marsOneDegreeFit <- train(low_noise, outcome_vector,
method = "earth",
tuneGrid = marsGrid,
trControl = ctrl
)
svmRTuned <- train(
solTrainXtrans, solTrainY,
method = "svmRadial",
tuneLength = 8,
epsilon = 0.01,
trControl = ctrl
)
svmRTuned <- train(
low_noise, outcome_vector,
method = "svmRadial",
tuneLength = 8,
epsilon = 0.01,
trControl = ctrl
)
svmRTuned <- train(
low_noise, outcome_vector,
method = "svmRadial",
tuneLength = 8,
epsilon = 0.01,
trControl = ctrl
)
competition_data <- read.csv("competition-data.csv", header = TRUE, sep = "," )
library(caret)
library(lattice)
library(pls)
library(tidyverse)
library(elasticnet)
library(corrplot)
library(tidyverse)
library(caret)
library(modelr)
library(ggplot2)
library(dplyr)
library(caTools)
svmRTuned <- train(
low_noise, outcome_vector,
method = "svmRadial",
tuneLength = 8,
epsilon = 0.01,
trControl = ctrl
)
min(svmRTuned$result$RMSE)
svmRTuned$bestTune
mtryGrid <- data.frame(
mtry = floor(seq(10, ncol(transformed_predictors),
length = 10))
)
set.seed(100)
rfTune <- train(x = transformed_predictors, y = outcome_vector,
method = "rf",
tuneGrid = mtryGrid,
ntree = 50,
importance = TRUE,
trControl = ctrl)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
competition_data <- read.csv("competition-data.csv", header = TRUE, sep = "," )
library(caret)
library(lattice)
library(pls)
library(tidyverse)
library(elasticnet)
library(corrplot)
library(tidyverse)
library(caret)
library(modelr)
library(ggplot2)
library(dplyr)
library(caTools)
View(competition_data)
competition_data %>%
ggplot(mapping = aes(x=outcome))+geom_bar()
outcome=c(competition_data$outcome)
train=competition_data %>% select(-outcome)
tooHigh <- findCorrelation(cor(train), cutoff = .9)
low_noise_train <- train[, -tooHigh]
set.seed(100)
lmTuneFiltered <- train(x = trainXfiltered, y = solTrainY,
method = "lm",
trControl = ctrl)
set.seed(100)
lmTuneFiltered <- train(x = low_noise_train, y = outcome,
method = "lm",
trControl = ctrl)
folds <- createFolds(outcome, k = 10, returnTrain = TRUE)
ctrl <- trainControl(method = "cv", index = folds)
set.seed(100)
lmTuneFiltered <- train(x = low_noise_train, y = outcome,
method = "lm",
trControl = ctrl)
lmTuneFiltered$results$RMSE
lmTuneFiltered$results$RMSE
set.seed(100)
plsTune <- train(x = low_noise_train, y = outcome,
method = "pls",
tuneGrid = expand.grid(ncomp = 1:50),
trControl = ctrl)
set.seed(100)
plsTune <- train(x = low_noise_train, y = outcome,
method = "pls",
tuneGrid = expand.grid(ncomp = 1:50),
trControl = ctrl)
set.seed(100)
plsTune <- train(x = low_noise_train, y = outcome,
method = "pls",
tuneGrid = expand.grid(ncomp = 1:50),
trControl = ctrl)
set.seed(100)
pcrTune <- train(x = solTrainXtrans, y = solTrainY,
method = "pcr",
tuneGrid = expand.grid(ncomp = 1:50),
trControl = ctrl)
set.seed(100)
pcrTune <- train(x = low_noise_train, y = outcome,
method = "pcr",
tuneGrid = expand.grid(ncomp = 1:50),
trControl = ctrl)
set.seed(100)
ridgeGrid <- expand.grid(lambda = seq(0, .1, length = 10))
ridgeTune <- train(x = solTrainXtrans, y = solTrainY,
method = "ridge",
tuneGrid = ridgeGrid,
trControl = ctrl,
preProc = c("center", "scale")
)
set.seed(100)
ridgeGrid <- expand.grid(lambda = seq(0, .1, length = 10))
ridgeTune <- train(x = low_noise_train, y = outcome,
method = "ridge",
tuneGrid = ridgeGrid,
trControl = ctrl,
preProc = c("center", "scale")
)
min(ridgeTune$results$RMSE)
ggplot(ridgeTune)
set.seed(100)
lassoGrid <- expand.grid(lambda = c(0),
fraction = seq(.1, 1, length = 15))
lassoTune <- train(x = solTrainXtrans, y = solTrainY,
method = "enet",
tuneGrid = lassoGrid,
trControl = ctrl,
preProc = c("center", "scale")
)
set.seed(100)
lassoGrid <- expand.grid(lambda = c(0),
fraction = seq(.1, 1, length = 15))
lassoTune <- train(x = low_noise_train, y = outcome,
method = "enet",
tuneGrid = lassoGrid,
trControl = ctrl,
preProc = c("center", "scale")
)
min(lassoTune$results$RMSE)
ggplot(lassoTune)
min(lassoTune$results$RMSE)
ggplot(lassoTune)
set.seed(100)
enetGrid <- expand.grid(lambda = seq(0.0, 0.02, length = 5),
fraction = seq(.1, 1, length = 5))
enetTune <- train(x = solTrainXtrans, y = solTrainY,
method = "enet",
tuneGrid = enetGrid,
trControl = ctrl,
preProc = c("center", "scale")
)
set.seed(100)
enetGrid <- expand.grid(lambda = seq(0.0, 0.02, length = 5),
fraction = seq(.1, 1, length = 5))
enetTune <- train(x = low_noise_train, y = outcome,
method = "enet",
tuneGrid = enetGrid,
trControl = ctrl,
preProc = c("center", "scale")
)
min(enetTune$results$RMSE)
ggplot(enetTune)
svmRTuned <- train(
low_noise_train, outcome,
method = "svmRadial",
preProc = c("center", "scale"),
tuneLength = 8,
epsilon = 0.01,
trControl = ctrl
)
min(svmRTuned$results$RMSE)
ggplot(svmRTuned)
set.seed(100)
nnetGrid <- expand.grid(
decay = c(0),
size = c(3)
)
nnetTune <- train(solTrainXtrans, solTrainY,
method = "nnet",
tuneGrid = nnetGrid,
trControl = ctrl,
preProc = c("center", "scale"),
linout = TRUE,
trace = FALSE
)
set.seed(100)
nnetGrid <- expand.grid(
decay = c(0),
size = c(3)
)
nnetTune <- train(low_noise_train, outcome,
method = "nnet",
tuneGrid = nnetGrid,
trControl = ctrl,
preProc = c("center", "scale"),
linout = TRUE,
trace = FALSE
)
min(nnetTune$results$RMSE)
ggplot(nnetTune)
nnetTune$results$RMSE
set.seed(100)
nnetGrid <- expand.grid(
decay = seq(0,100,length=10),
size = c(3)
)
nnetTune <- train(low_noise_train, outcome,
method = "nnet",
tuneGrid = nnetGrid,
trControl = ctrl,
preProc = c("center", "scale"),
linout = TRUE,
trace = FALSE
)
min(nnetTune$results$RMSE)
ggplot(nnetTune)
min(nnetTune$results$RMSE)
ggplot(nnetTune)
marsGrid <- expand.grid(.degree = 1:2, .nprune = c(20, 30, 40, 50))
marsFit <- train(low_noise_train, outcome,
method = "earth",
tuneGrid = marsGrid,
trControl = ctrl
)
min(marsFit$results$RMSE)
ggplot(marsFit)
min(marsFit$results$RMSE)
ggplot(marsFit)
svmLinearTuned <- train(
low_noise_train, outcome,
method = "svmLinear",
preProc = c("center", "scale"),
tuneLength = 8,
epsilon = 0.01,
trControl = ctrl
)
svmLinearTuned$results$RMSE
set.seed(100)
m5Tune <- train(solTrainXtrans, solTrainY,
method = "M5",
trControl = ctrl,
control = Weka_control(M = 70)
)
set.seed(100)
m5Tune <- train(low_noise_train, outcome,
method = "M5",
trControl = ctrl,
control = Weka_control(M = 70)
)
competition_data <- read.csv("competition-data.csv", header = TRUE, sep = "," )
library(caret)
library(lattice)
library(pls)
library(tidyverse)
library(elasticnet)
library(corrplot)
library(tidyverse)
library(caret)
library(modelr)
library(ggplot2)
library(dplyr)
library(caTools)
library(RWeka)
install.packages("Rweka")
install.packages("RWeka")
competition_data <- read.csv("competition-data.csv", header = TRUE, sep = "," )
library(caret)
library(lattice)
library(pls)
library(tidyverse)
library(elasticnet)
library(corrplot)
library(tidyverse)
library(caret)
library(modelr)
library(ggplot2)
library(dplyr)
library(caTools)
library(RWeka)
competition_data <- read.csv("competition-data.csv", header = TRUE, sep = "," )
library(caret)
library(lattice)
library(pls)
library(tidyverse)
library(elasticnet)
library(corrplot)
library(tidyverse)
library(caret)
library(modelr)
library(ggplot2)
library(dplyr)
library(caTools)
library(RWeka)
set.seed(100)
m5Tune <- train(low_noise_train, outcome,
method = "M5",
trControl = ctrl,
control = Weka_control(M = 70)
)
m5Tune$results$RMSE
min(m5Tune$results$RMSE)
ggplot(m5Tune)
min(m5Tune$results$RMSE)
set.seed(100)
rfTune <- train(x = solTrainXtrans, y = solTrainY,
method = "rf",
tuneGrid = mtryGrid,
ntree = 50,
importance = TRUE,
trControl = ctrl)
set.seed(100)
rfTune <- train(x = low_noise_train, y = outcome,
method = "rf",
tuneGrid = mtryGrid,
ntree = 50,
importance = TRUE,
trControl = ctrl)
mtryGrid <- data.frame(
mtry = floor(seq(10, ncol(solTrainXtrans),
length = 10))
)
mtryGrid <- data.frame(
mtry = floor(seq(10, ncol(low_noise_train),
length = 10))
)
set.seed(100)
rfTune <- train(x = low_noise_train, y = outcome,
method = "rf",
tuneGrid = mtryGrid,
ntree = 50,
importance = TRUE,
trControl = ctrl)
min(rfTune$results$RMSE)
ggplot(rfTune)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
competition_test <- read.csv("competition-test-x-values.csv", header = TRUE, sep = "," )
predictions<-predict(rfTune,newdata = competition_test,na)
competition_test <- read.csv("competition-test-x-values.csv", header = TRUE, sep = "," )
predictions<-predict(rfTune,newdata = competition_test)
write.csv(predictions,"prediction.csv",roll.names=FALSE)
competition_test <- read.csv("competition-test-x-values.csv", header = TRUE, sep = "," )
predictions<-predict(rfTune,newdata = competition_test)
write.csv(predictions,"prediction.csv",row.names = FALSE)
